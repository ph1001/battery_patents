{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5cd8b1",
   "metadata": {},
   "source": [
    "## Window formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b26d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.output_result { max-width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:98% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d27c07",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "main_path_mac = '/Users/philippmetzger/Documents/GitHub/battery_patents/'\n",
    "main_path_ssd = '/Volumes/Samsung Portable SSD T3 Media/'\n",
    "\n",
    "import sys\n",
    "packages_path = main_path_mac+'/07 Packages'\n",
    "sys.path.append(packages_path)\n",
    "\n",
    "from helpers import (current_time_string,\n",
    "                              image_saver,\n",
    "                              country_labels_dict,\n",
    "                              ctry_code_name_dict,\n",
    "                              message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f39c99",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225e6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_everything_is_there(datasets_list, feature):\n",
    "    \n",
    "    \"\"\"A function that takes a list of datasets and a feature name and returns the sorted mins and maxs of this \n",
    "    feature for each dataset in the list.\"\"\"\n",
    "\n",
    "    beginnings_ends_list = []\n",
    "    \n",
    "    for i in range(len(datasets_list)):\n",
    "\n",
    "        beginning = min(datasets_list[i][feature])\n",
    "        end = max(datasets_list[i][feature])\n",
    "\n",
    "        beginnings_ends_list.append((beginning, end))\n",
    "\n",
    "    beginnings_ends_list.sort(key=lambda x: x[0])\n",
    "    \n",
    "    return beginnings_ends_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dadc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_all_applicants_and_inventors_are_present(data_to_check):\n",
    "    \n",
    "    appln_ids = pd.unique(data_to_check['appln_id'])\n",
    "\n",
    "    for appln_id in tqdm(appln_ids):\n",
    "\n",
    "        data_this_appln_id = data_to_check[data_to_check['appln_id'] == appln_id]\n",
    "\n",
    "        nb_applicants = list(set(data_this_appln_id['nb_applicants']))\n",
    "        nb_inventors = list(set(data_this_appln_id['nb_inventors']))\n",
    "\n",
    "        if ((len(nb_applicants) > 1) or (len(nb_inventors) > 1)):\n",
    "            print(appln_id)\n",
    "            print('Either nb_applicants or nb_inventors has more than one value.')\n",
    "            break\n",
    "\n",
    "        nb_applicants = nb_applicants[0]\n",
    "        nb_inventors = nb_inventors[0]\n",
    "\n",
    "        data_this_appln_id_applicants = data_this_appln_id[data_this_appln_id['applt_seq_nr'] > 0]\n",
    "        data_this_appln_id_inventors = data_this_appln_id[data_this_appln_id['invt_seq_nr'] > 0]\n",
    "\n",
    "        if (len(data_this_appln_id_applicants) != nb_applicants):\n",
    "            print(appln_id)\n",
    "            print('nb_applicants is not equal to the number of listed applicants.')\n",
    "            print()\n",
    "\n",
    "        if (len(data_this_appln_id_inventors) != nb_inventors):\n",
    "            print(appln_id)\n",
    "            print('nb_inventors is not equal to the number of listed inventors.')\n",
    "            print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feaf21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_docdb_family_size_is_equal_to_number_of_applications(data_to_check):\n",
    "\n",
    "    reduced = data_to_check[['docdb_family_id','appln_id','docdb_family_size']].drop_duplicates()\n",
    "\n",
    "    family_ids = pd.unique(reduced['docdb_family_id'])\n",
    "\n",
    "    for family_id in tqdm(family_ids):\n",
    "\n",
    "        reduced_this_family_id = reduced[reduced['docdb_family_id'] == family_id]\n",
    "\n",
    "        len_ = len(reduced_this_family_id)\n",
    "        docdb_family_size = list(set(reduced_this_family_id['docdb_family_size']))\n",
    "\n",
    "        if len(docdb_family_size) > 1:\n",
    "            print(str(family_id)+': There is more than one docdb_family_size.')\n",
    "            break\n",
    "\n",
    "        docdb_family_size = docdb_family_size[0]\n",
    "\n",
    "        if (len_ != docdb_family_size):\n",
    "            print(str(family_id)+': docdb_family_size is not equal to the number of applications contained in this family')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952f059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dict(df):\n",
    "    \"\"\"Functin that turns the first two columns of a given DataFrame into a dictionary, with the first column being\n",
    "    the keys and the second column being the values.\"\"\"\n",
    "    \n",
    "    # Convert first column to list\n",
    "    first_col = list(df.iloc[:,0])\n",
    "    print(len(first_col))\n",
    "    \n",
    "    # Convert first column to list\n",
    "    second_col = list(df.iloc[:,1])\n",
    "    print(len(second_col))\n",
    "    \n",
    "    if len(first_col) != len(second_col):\n",
    "        print('Something is wrong.')\n",
    "        return\n",
    "    \n",
    "    # Define an empty dictionary and fill it with the two columns' entries\n",
    "    dict_ = {}\n",
    "    for i in range(len(first_col)): \n",
    "        \n",
    "        # Split this string into the IDs it contains, delete duplicates and rejoin it into one string\n",
    "        # Then save it in the dictionary\n",
    "        dict_[first_col[i]] = ','.join(list(set(second_col[i].split(','))))\n",
    "        \n",
    "    # Return it\n",
    "    return dict_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c831239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New version from 3 Nov 2021\n",
    "# Separates applicants and inventors nulls\n",
    "\n",
    "def loop_over_family_ids(data, family_ids, check_imputed_person_ctry_code):\n",
    "    \"\"\"\n",
    "    This function loops over all family_ids and identifies the ones that have no country codes in the rows\n",
    "    corresponding to their applicants.\n",
    "    \n",
    "    Returns:\n",
    "    Of those families it returns the han_names and the family_ids for further processing.\n",
    "    \"\"\"\n",
    "\n",
    "    nulls_han_names = []\n",
    "    nulls_han_names.append([])\n",
    "    nulls_han_names.append([])\n",
    "    nulls_han_names\n",
    "    \n",
    "    nulls_family_ids = []\n",
    "    nulls_family_ids.append([])\n",
    "    nulls_family_ids.append([])\n",
    "    nulls_family_ids\n",
    "    \n",
    "    for family_id in tqdm(family_ids):\n",
    "\n",
    "        # Get these entries\n",
    "        data_this_family_id = data[data['docdb_family_id'] == family_id]\n",
    "        data_this_family_id_applicants = data_this_family_id[data_this_family_id['applt_seq_nr']>0]\n",
    "        data_this_family_id_inventors = data_this_family_id[data_this_family_id['invt_seq_nr']>0]\n",
    "        \n",
    "        for i, item in enumerate([data_this_family_id_applicants, data_this_family_id_inventors]):\n",
    "            \n",
    "            if len(item) > 0:\n",
    "            \n",
    "                # Get their unique country codes. Check original person_ctry_code column or person_ctry_code_imputed if\n",
    "                # specified through the passed argument check_imputed_person_ctry_code\n",
    "                if check_imputed_person_ctry_code == False:\n",
    "                    country_codes_this_family_id = list(set(item['person_ctry_code']))\n",
    "                else:\n",
    "                    country_codes_this_family_id = list(set(item['person_ctry_code_imputed']))\n",
    "                    \n",
    "                #print(country_codes_this_family_id)\n",
    "                #print()\n",
    "                \n",
    "                #if np.nan in country_codes_this_family_id:\n",
    "                #    print(country_codes_this_family_id)\n",
    "                \n",
    "                # If this family has no country codes, save this family ID and the han_names that are included in it\n",
    "                if (country_codes_this_family_id == [np.nan]) or (country_codes_this_family_id == []):\n",
    "                    \n",
    "                    #print(country_codes_this_family_id)\n",
    "                    #print()\n",
    "\n",
    "                    nulls_han_names[i].extend(list(set(data_this_family_id['han_name'])))\n",
    "                    nulls_family_ids[i].append(family_id)\n",
    "            \n",
    "    return nulls_han_names, nulls_family_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c0aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_column(col_name, new_col):\n",
    "    \n",
    "    col_index = list(data).index(col_name)\n",
    "    data.drop(col_name, axis=1, inplace=True)\n",
    "    data.insert(col_index, col_name, new_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6d97a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_data():\n",
    "    \"\"\"\n",
    "    Function that tags each patent family either as singleton or as IPF. If it a patent family is neither, the tag '-'\n",
    "    is given.\n",
    "\n",
    "    Returns: tags_dict - A dictionary containing all family IDs present in the given dataset as keys and their\n",
    "    tag given by this function.\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop over all family IDs and save those in their entirety that correspond to an international patent family (IPF)\n",
    "\n",
    "    # Get all family IDs present in this dataset\n",
    "    family_ids = pd.unique(data['docdb_family_id'])\n",
    "    \n",
    "    # Initialise an empty dictionary for saving each family_id's tag\n",
    "    tags_dict = {}\n",
    "\n",
    "    # Loop over all family IDs\n",
    "    print('Creating tags...')\n",
    "    for family_id in tqdm(family_ids):\n",
    "\n",
    "        # Get this family ID's data\n",
    "        data_this_family_id = data[data['docdb_family_id']==family_id]\n",
    "        \n",
    "        # Get all application authorities present in this family ID (without duplicates)\n",
    "        appln_auth_this_id = list(set(data_this_family_id['appln_auth']))\n",
    "\n",
    "        #print(appln_auth_this_id)\n",
    "        #print()\n",
    "\n",
    "        \n",
    "        # Singletons\n",
    "        #\n",
    "        # Page 28 of 36 of\n",
    "        # \"International patent families: from application strategies to statistical indicators\" (DechezleprÃªtre):\n",
    "        # \"we refer to patents filed in only one country and that are the only member of their patent family as\n",
    "        # singletons.\"\n",
    "        #\n",
    "        is_singleton = False\n",
    "        \n",
    "        # Create a version of appln_auth_this_id with all entries corresponding to international or regional patent\n",
    "        # offices removed\n",
    "        appln_auth_non_international_non_regional = []\n",
    "        for item in appln_auth_this_id:\n",
    "            if not item in international_and_regional_appln_auth:\n",
    "                appln_auth_non_international_non_regional.append(item)\n",
    "        \n",
    "        # Get the number of distinct applications in this patent family\n",
    "        num_appln_ids_this_id = len(list(set(data_this_family_id['appln_id'])))\n",
    "\n",
    "        # If\n",
    "        # - a patent family consists of only one application (contains only one application ID) and\n",
    "        # - the application authority of this application is a national patent office\n",
    "        # this patent family is tagged as singleton.\n",
    "        if ((num_appln_ids_this_id == 1) and (len(appln_auth_non_international_non_regional) == 1)):\n",
    "            is_singleton = True\n",
    "            \n",
    "            \n",
    "        # IPFs:\n",
    "        is_IPF = False\n",
    "        IPFs_list = []\n",
    "        \n",
    "        # IPF criterion 1: Patent families that contain international or regional applications are kept\n",
    "\n",
    "        # Check if the patent family that corresponds to this family ID contains an international patent \n",
    "        # application or a patent application at a regional patent office \n",
    "        for appln_auth in appln_auth_this_id:\n",
    "            if (appln_auth in international_and_regional_appln_auth):\n",
    "                is_IPF = True\n",
    "\n",
    "        # IPF criterion 2: Patent families that contain applications from at least two distinct national patent \n",
    "        # offices are kept\n",
    "\n",
    "        # If there are two or more remaining patent offices in appln_auth_non_international_non_regional (which \n",
    "        # contains only national patent offices), set is_IPF to True\n",
    "        if len(appln_auth_non_international_non_regional) >= 2:\n",
    "            is_IPF = True\n",
    "            \n",
    "        \n",
    "        if is_singleton and is_IPF:\n",
    "            print(str(family_id)+': Something is wrong. This family is both singleton and IPF.')\n",
    "            \n",
    "            \n",
    "        if is_singleton:\n",
    "            tags_dict[family_id] = 'singleton'\n",
    "        elif is_IPF:\n",
    "            tags_dict[family_id] = 'IPF'\n",
    "        else:\n",
    "            tags_dict[family_id] = 'neither'\n",
    "\n",
    "            \n",
    "    family_id_column = list(data['docdb_family_id'])\n",
    "    len_ = len(family_id_column)\n",
    "    tags_colum = [''] * len_\n",
    "    \n",
    "    print('Applying tags...')\n",
    "    for i in tqdm(range(len_)):\n",
    "        tags_colum[i] = tags_dict[family_id_column[i]]\n",
    "    \n",
    "    # Insert tag column into data\n",
    "    # If it already exists, delete the old version first\n",
    "    if 'tag' in list(data):\n",
    "        data.drop(columns = 'tag', inplace = True)\n",
    "    data.insert(0, 'tag', tags_colum)        \n",
    "\n",
    "    return tags_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82a23d",
   "metadata": {},
   "source": [
    "## Assemble raw datasets downloaded from PATSTAT into one dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08e964",
   "metadata": {},
   "source": [
    "### Define time segments we're interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "357a441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019_1', '2019_2']\n"
     ]
    }
   ],
   "source": [
    "years = list(range(1999,2019))\n",
    "\n",
    "years_str = []\n",
    "\n",
    "for item in years:\n",
    "    years_str.append(str(item))\n",
    "    \n",
    "years_str.extend(['2019_1', '2019_2'])\n",
    "\n",
    "years = years_str\n",
    "    \n",
    "print(years)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b86209",
   "metadata": {},
   "source": [
    "### Read raw datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e902e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45175c89ecca41d4a752e8d8831aea7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = []\n",
    "for i in tqdm(years):\n",
    "    \n",
    "    path = main_path_ssd + 'Dataset saves/04 From 15 Nov 2021 (release of 2021 Autumn edition)/00 data_patstat/with rest of TLS209_APPLN_IPC/'+str(i)+'.csv'\n",
    "    \n",
    "    files.append(pd.read_csv(path, delimiter = \";\", low_memory = False, na_values=['', ' ', '  '], keep_default_na = False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783aaa9",
   "metadata": {},
   "source": [
    "### Check if all data is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cd834d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1999-01-01', '2016-03-01'),\n",
       " ('2000-01-01', '2020-12-29'),\n",
       " ('2001-01-01', '2019-07-16'),\n",
       " ('2002-01-01', '2021-03-08'),\n",
       " ('2003-01-01', '2021-07-29'),\n",
       " ('2004-01-01', '2021-05-27'),\n",
       " ('2005-01-01', '2020-11-05'),\n",
       " ('2006-01-01', '2021-06-24'),\n",
       " ('2007-01-01', '2021-07-07'),\n",
       " ('2008-01-01', '2021-07-01'),\n",
       " ('2009-01-01', '2021-07-29'),\n",
       " ('2010-01-01', '2021-07-29'),\n",
       " ('2011-01-01', '2021-07-29'),\n",
       " ('2012-01-01', '2021-07-27'),\n",
       " ('2013-01-01', '2021-07-29'),\n",
       " ('2014-01-01', '2021-07-26'),\n",
       " ('2015-01-01', '2021-07-29'),\n",
       " ('2016-01-01', '2021-07-29'),\n",
       " ('2017-01-01', '2021-07-30'),\n",
       " ('2018-01-01', '2021-07-30'),\n",
       " ('2019-01-01', '2021-07-30'),\n",
       " ('2019-07-01', '2021-07-30')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_everything_is_there(files, 'earliest_publn_date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf2018",
   "metadata": {},
   "source": [
    "### Check if docdb_family_size is equal to the number of applications in each family\n",
    "#### If everything is as it should be, this prints only the year / segment numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79013caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d854fd07a674f19965f9b68912106f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9576f9735d49c99548aacecbfb6c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a702ee0aa64e80aa2fbb558174f4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87897be5110f4c768869e7b730242208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bad8c7e65b40849eae96a17faa9c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167cf012dafa44c1a0ab306ba011dbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a424c35df4f44d591bc2ee7fb6cf1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9483f961424d21bac98b62b58057df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fa579d3bb040fbb3a8f74e6d07ead8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfedceced6d4377b33314246317c51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93fe361d1ad4ca0b828aabe04703061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9aa9cc281584de4b36d22f3a827dbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72c2adc19ef441dbe8962b61229f050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80382118f0c942d49387c6ef09457cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b5c8b167ca4179bc7dd62fcbbb9b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e4a4dbbbfb48cb9dd15ccaa26edf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0667e2a929404d825dc904382e9fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208518602c314254b507858659b57df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50d5e8ca70e420e872aae27b11a5f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63600c97f68472cae0ae1e607c025d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256a410a09a645f2aebc012a89677c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb8b615dfa04d249b744ab64930ddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "    \n",
    "    print(years[i])\n",
    "    check_if_docdb_family_size_is_equal_to_number_of_applications(files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b86e7a",
   "metadata": {},
   "source": [
    "### Check if min(earliest_publn_date) for each family ID is inside the time frame\n",
    "#### This prints the minimum and the maximum of each segments intra-family earliest publication dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ebf007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999-01-01\n",
      "1999-12-31\n",
      "\n",
      "2000-01-01\n",
      "2000-12-30\n",
      "\n",
      "2001-01-01\n",
      "2001-12-31\n",
      "\n",
      "2002-01-01\n",
      "2002-12-31\n",
      "\n",
      "2003-01-01\n",
      "2003-12-31\n",
      "\n",
      "2004-01-01\n",
      "2004-12-31\n",
      "\n",
      "2005-01-01\n",
      "2005-12-31\n",
      "\n",
      "2006-01-01\n",
      "2006-12-29\n",
      "\n",
      "2007-01-01\n",
      "2007-12-31\n",
      "\n",
      "2008-01-01\n",
      "2008-12-31\n",
      "\n",
      "2009-01-01\n",
      "2009-12-31\n",
      "\n",
      "2010-01-01\n",
      "2010-12-31\n",
      "\n",
      "2011-01-01\n",
      "2011-12-31\n",
      "\n",
      "2012-01-01\n",
      "2012-12-31\n",
      "\n",
      "2013-01-01\n",
      "2013-12-31\n",
      "\n",
      "2014-01-01\n",
      "2014-12-31\n",
      "\n",
      "2015-01-01\n",
      "2015-12-31\n",
      "\n",
      "2016-01-01\n",
      "2016-12-30\n",
      "\n",
      "2017-01-01\n",
      "2017-12-31\n",
      "\n",
      "2018-01-01\n",
      "2018-12-31\n",
      "\n",
      "2019-01-01\n",
      "2019-06-28\n",
      "\n",
      "2019-07-01\n",
      "2019-12-31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(files)):\n",
    "\n",
    "    min_earliest_publn_date_this_family_id = files[i][['docdb_family_id','earliest_publn_date']].groupby('docdb_family_id')['earliest_publn_date'].agg('min')\n",
    "\n",
    "    print(min(min_earliest_publn_date_this_family_id))\n",
    "    print(max(min_earliest_publn_date_this_family_id))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22bbb18",
   "metadata": {},
   "source": [
    "### Concatenate everything into one DataFrame and sort rows to make it more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precious-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(files, axis=0).reset_index(drop=True)\n",
    "data = data.sort_values(by = ['docdb_family_id', 'appln_id', 'invt_seq_nr', 'applt_seq_nr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a07468d",
   "metadata": {},
   "source": [
    "### Check if import respective to nan values worked properly, i.e. if 'NA' is included in dataset as a country code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "178eb039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = list(set(data['person_ctry_code']))\n",
    "countries.remove(np.nan)\n",
    "'NA' in sorted(countries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a903037",
   "metadata": {},
   "source": [
    "### There are no duplicates to remove. Show this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741f2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4086532\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_2 = data.copy()\n",
    "data_2 = data_2.drop_duplicates()\n",
    "print(len(data_2))\n",
    "print(len(data) == len(data_2))\n",
    "del data_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0238ee",
   "metadata": {},
   "source": [
    "## Harmonize earliest publication date and earliest publication year on family ID level\n",
    "### Compute earliest_publn_date_this_family_id and earliest_publn_year_this_family_id for each family ID and add them as a new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7240bb3",
   "metadata": {},
   "source": [
    "### Get the dates using group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e779d45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docdb_family_id\n",
       "1574492     2015-12-17\n",
       "3479677     2001-11-26\n",
       "3480472     2000-07-20\n",
       "3480531     2000-07-20\n",
       "3486787     2000-03-27\n",
       "               ...    \n",
       "74557388    2015-09-30\n",
       "74686853    2004-07-15\n",
       "74844536    2004-06-15\n",
       "74871121    2019-06-13\n",
       "76483790    2019-07-05\n",
       "Name: earliest_publn_date, Length: 610359, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_earliest_publn_date_this_family_id = data[['docdb_family_id','earliest_publn_date']].groupby('docdb_family_id')['earliest_publn_date'].agg('min')\n",
    "min_earliest_publn_date_this_family_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39af96c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docdb_family_id\n",
       "1574492     2015\n",
       "3479677     2001\n",
       "3480472     2000\n",
       "3480531     2000\n",
       "3486787     2000\n",
       "            ... \n",
       "74557388    2015\n",
       "74686853    2004\n",
       "74844536    2004\n",
       "74871121    2019\n",
       "76483790    2019\n",
       "Name: earliest_publn_year, Length: 610359, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_earliest_publn_year_this_family_id = data[['docdb_family_id','earliest_publn_year']].groupby('docdb_family_id')['earliest_publn_year'].agg('min')\n",
    "min_earliest_publn_year_this_family_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c55ad",
   "metadata": {},
   "source": [
    "### Turn them into dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "341a6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_earliest_publn_date_this_family_id_dict = dict(min_earliest_publn_date_this_family_id)\n",
    "#min_earliest_publn_date_this_family_id_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ca93629",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_earliest_publn_year_this_family_id_dict = dict(min_earliest_publn_year_this_family_id)\n",
    "#min_earliest_publn_year_this_family_id_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc55ef",
   "metadata": {},
   "source": [
    "### Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38be93a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f0cad4a472485ea8dc975ee3dd38bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4086532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "family_id_column = list(data['docdb_family_id'])\n",
    "len_ = len(family_id_column)\n",
    "\n",
    "earliest_publn_date_this_family_id_column = [''] * len_\n",
    "earliest_publn_year_this_family_id_column = [9999] * len_\n",
    "\n",
    "for i in tqdm(range(len_)):\n",
    "    \n",
    "    earliest_publn_date_this_family_id_column[i] = min_earliest_publn_date_this_family_id_dict[family_id_column[i]]\n",
    "    earliest_publn_year_this_family_id_column[i] = min_earliest_publn_year_this_family_id_dict[family_id_column[i]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67dccf",
   "metadata": {},
   "source": [
    "### Get the index of 'earliest_publn_date' and insert the two new columns on the right next to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79171115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_publn_date_earliest_publn_year_index = max(list(data).index('earliest_publn_date'), list(data).index('earliest_publn_year'))\n",
    "earliest_publn_date_earliest_publn_year_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf6cc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(earliest_publn_date_earliest_publn_year_index + 1, 'earliest_publn_date_this_family_id', earliest_publn_date_this_family_id_column)\n",
    "data.insert(earliest_publn_date_earliest_publn_year_index + 2, 'earliest_publn_year_this_family_id', earliest_publn_year_this_family_id_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f768495",
   "metadata": {},
   "source": [
    "### Check minima and maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee8c7a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1999-01-01'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sorted(list(set(data['earliest_publn_date_this_family_id']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1697a0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-12-31'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sorted(list(set(data['earliest_publn_date_this_family_id']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0ead76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sorted(list(set(data['earliest_publn_year_this_family_id']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b37e409a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sorted(list(set(data['earliest_publn_year_this_family_id']))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e055c3",
   "metadata": {},
   "source": [
    "### Check that neither '' nor 9999 are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7288900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'' in list(set(data['earliest_publn_date_this_family_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38179e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9999 in list(set(data['earliest_publn_year_this_family_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d62cd",
   "metadata": {},
   "source": [
    "### Consistency check\n",
    "#### If everything is as it should be, this prints nothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d86c41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    family_ids = pd.unique(data['docdb_family_id'])\n",
    "\n",
    "    for i in tqdm(range(len(family_ids))):\n",
    "\n",
    "        data_this_family_id = data[data['docdb_family_id'] == family_ids[i]]\n",
    "\n",
    "        earliest_publn_date_this_family_id = list(set(data_this_family_id['earliest_publn_date_this_family_id']))\n",
    "        earliest_publn_year_this_family_id = list(set(data_this_family_id['earliest_publn_year_this_family_id']))\n",
    "\n",
    "        if ((len(earliest_publn_date_this_family_id) > 1) or (len(earliest_publn_year_this_family_id) > 1)):\n",
    "            print('There is more than on _this_family_id entry.')\n",
    "\n",
    "        earliest_publn_date_this_family_id = earliest_publn_date_this_family_id[0]   \n",
    "        #print(earliest_publn_date_this_family_id)\n",
    "\n",
    "        earliest_publn_year_this_family_id = earliest_publn_year_this_family_id[0]\n",
    "        #print(earliest_publn_year_this_family_id)\n",
    "\n",
    "        if earliest_publn_date_this_family_id != min(data_this_family_id['earliest_publn_date']):\n",
    "            print(str(family_ids[i])+': earliest_publn_date_this_family_id not the same as actual min')\n",
    "\n",
    "        if earliest_publn_year_this_family_id != min(data_this_family_id['earliest_publn_year']):\n",
    "            print(str(family_ids[i])+': earliest_publn_year_this_family_id not the same as actual min')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b4d4e9",
   "metadata": {},
   "source": [
    "## Tag data as \"IPF\", \"singleton\", or \"neither\"\n",
    "### IPF definition:\n",
    "\"An IPF is defined as a patent family that includes a published **international patent\n",
    "application**, a published **patent application at a regional patent office**, or published\n",
    "patent applications **at two or more national patent offices**. The regional patent\n",
    "offices are the African Intellectual Property Organization, the African Regional\n",
    "Intellectual Property Organization, the Eurasian Patent Organization, the EPO and\n",
    "the Patent Office of the Cooperation Council for the Arab States of the Gulf.\"\n",
    "<br />\n",
    "IEA & EPO, Innovation in batteries and electricity storage: A global analysis based on patent data (September 2020)\n",
    "<br />\n",
    "Page 38\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bffcd",
   "metadata": {},
   "source": [
    "### Define what international, regional and national application authorities are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94a40cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AP', 'AR', 'AT', 'AU', 'BE', 'BG', 'BR', 'CA', 'CH', 'CL', 'CN', 'CO', 'CR', 'CU', 'CY', 'CZ', 'DE', 'DK', 'DO', 'DZ', 'EA', 'EC', 'EE', 'EG', 'EP', 'ES', 'FI', 'FR', 'GB', 'GC', 'GE', 'GR', 'GT', 'HK', 'HR', 'HU', 'ID', 'IE', 'IL', 'IN', 'IS', 'IT', 'JO', 'JP', 'KR', 'LT', 'LU', 'LV', 'MA', 'MC', 'MD', 'ME', 'MX', 'MY', 'NI', 'NL', 'NO', 'NZ', 'OA', 'PA', 'PE', 'PH', 'PL', 'PT', 'RO', 'RS', 'RU', 'SA', 'SE', 'SG', 'SI', 'SK', 'SM', 'SU', 'SV', 'TN', 'TR', 'TW', 'UA', 'US', 'UY', 'WO', 'YU', 'ZA']\n",
      "\n",
      "['IB', 'WO']\n",
      "\n",
      "['OA', 'AP', 'EA', 'EP', 'GC']\n",
      "\n",
      "['IB', 'WO', 'OA', 'AP', 'EA', 'EP', 'GC']\n",
      "\n",
      "['IB', 'WO', 'EP']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all application authorities present in this data\n",
    "all_appln_auth = sorted(list(set(data['appln_auth'])))\n",
    "print(all_appln_auth)\n",
    "print()\n",
    "\n",
    "\n",
    "# Define list of international patent offices\n",
    "international_appln_auth = ['IB', # International Bureau of the World Intellectual Property Organization (WIPO)\n",
    "                            # (For completeness. Apparently it does not exist anymore.)\n",
    "                            'WO' # World Intellectual Property Organization (WIPO) (International Bureau of)\n",
    "                           ]\n",
    "print(international_appln_auth)\n",
    "print()\n",
    "\n",
    "\n",
    "# Define list of regional patent offices\n",
    "regional_appln_auth = ['OA', # African Intellectual Property Organization\n",
    "                       'AP', # African Regional Intellectual Property Organization\n",
    "                       'EA', # Eurasian Patent Organization\n",
    "                       'EP', # EPO\n",
    "                       'GC' # Patent Office of the Cooperation Council for the Arab States of the Gulf\n",
    "                      ]\n",
    "print(regional_appln_auth)\n",
    "print()\n",
    "\n",
    "\n",
    "# Save international and regional patent offices in one list\n",
    "international_and_regional_appln_auth = international_appln_auth.copy()\n",
    "international_and_regional_appln_auth.extend(regional_appln_auth)\n",
    "print(international_and_regional_appln_auth)\n",
    "print()\n",
    "\n",
    "# Save international patent offices and EPO in one list\n",
    "international_and_EPO = international_appln_auth.copy()\n",
    "international_and_EPO.append('EP')\n",
    "print(international_and_EPO)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a807e",
   "metadata": {},
   "source": [
    "### Tag data: IPC / singleton / neither"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bbf1c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4fa59afa87442296f819551649247c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying tags...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00402b9d37044bde8c34bd16bcf2cbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4086532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_dict = tag_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "416eb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save battery data (all, tagged) to csv\n",
    "filename = 'data_batteries_'+current_time_string()+'_ipf_tagged.csv'\n",
    "data.to_csv(path_or_buf=filename, sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5457f30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:\n",
      "/Volumes/Samsung Portable SSD T3 Media/Dataset saves/04 From 15 Nov 2021 (release of 2021 Autumn edition)/01 Preprocessed/01 all data, ipf tagged/data_batteries_2022-01-04_1659_all_data_ipf_tagged.csv\n"
     ]
    }
   ],
   "source": [
    "# Read battery data (all, tagged) to csv\n",
    "dataset_name = 'data_batteries_2022-01-04_1659_ipf_tagged'\n",
    "\n",
    "path = main_path_ssd+'Dataset saves/04 From 15 Nov 2021 (release of 2021 Autumn edition)/01 Preprocessed/01 all data, ipf tagged/'+dataset_name+'.csv'\n",
    "\n",
    "print('Loading data from:')\n",
    "print(path)\n",
    "\n",
    "data = pd.read_csv(path, delimiter = \";\", low_memory = False, na_values=['', ' ', '  '], keep_default_na = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df0fb6",
   "metadata": {},
   "source": [
    "### Check share of IPFs out of all patent families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71a833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ipf = data[data['tag'] == 'IPF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d1411de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2201507637308535"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(data[data['tag'] == 'IPF']['docdb_family_id']))) / len(list(set(data['docdb_family_id'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bffd759",
   "metadata": {},
   "source": [
    "## Add cited_docdb_family_ids and cited_by_docdb_family_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c6d7b6",
   "metadata": {},
   "source": [
    "### Load citation datasets downloaded from PATSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76744bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/philippmetzger/Documents/GitHub/battery_patents/03 Extra data/PATSTAT citations (to and from H01M% + Charging)/'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_beginning = main_path_mac+\"03 Extra data/PATSTAT citations (to and from H01M% + Charging)/\"\n",
    "path_beginning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dac0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_beginning+\"cited_docdb_family_ids.csv\"\n",
    "cited_df = pd.read_csv(path, delimiter = \";\", na_values=[\"\"], keep_default_na = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "210c45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_beginning+\"cited_by_docdb_family_ids.csv\"\n",
    "cited_by_df = pd.read_csv(path, delimiter = \";\", na_values=[\"\"], keep_default_na = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db27b74",
   "metadata": {},
   "source": [
    "### Get percentage of rows with nan for both DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62d501ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(len(cited_df[cited_df['cited_docdb_family_ids'].isna()]) / len(cited_df))\n",
    "print(len(cited_by_df[cited_by_df['cited_by_docdb_family_ids'].isna()]) / len(cited_by_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ec7b4",
   "metadata": {},
   "source": [
    "### Two more checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ddcace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# First column of cited_df and cited_by_df the same?\n",
    "print(list(cited_df['docdb_family_id'].values) == list(cited_by_df['docdb_family_id'].values))\n",
    "\n",
    "# Second column of cited_df and cited_by_df the same?\n",
    "print(list(cited_df['cited_docdb_family_ids'].values) == list(cited_by_df['cited_by_docdb_family_ids'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60856cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396442\n",
      "396442\n",
      "\n",
      "492829\n",
      "492829\n"
     ]
    }
   ],
   "source": [
    "# Check row count. Remove nans from cited_df if present. Check row count again. \n",
    "print(len(cited_df))\n",
    "cited_df_non_na = cited_df[~cited_df['cited_docdb_family_ids'].isna()]\n",
    "print(len(cited_df_non_na))\n",
    "print()\n",
    "\n",
    "# Check row count. Remove nans from cited_by_df if present. Check row count again. \n",
    "print(len(cited_by_df))\n",
    "cited_by_df_non_na = cited_by_df[~cited_by_df['cited_by_docdb_family_ids'].isna()]\n",
    "print(len(cited_by_df_non_na))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238fa77",
   "metadata": {},
   "source": [
    "### Turn dataframes into dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f966a88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396442\n",
      "396442\n"
     ]
    }
   ],
   "source": [
    "cited_dict = df_to_dict(cited_df_non_na)\n",
    "#cited_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3279ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492829\n",
      "492829\n"
     ]
    }
   ],
   "source": [
    "cited_by_dict = df_to_dict(cited_by_df_non_na)\n",
    "#cited_by_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276c56e",
   "metadata": {},
   "source": [
    "### Check one example family ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "366d9f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patent family with docdb family ID 582072\n",
      "cited:\n",
      "22922260,757553\n",
      "was cited by:\n",
      "9865521,52470274\n"
     ]
    }
   ],
   "source": [
    "id_ = 582072\n",
    "print('Patent family with docdb family ID', id_)\n",
    "print('cited:')\n",
    "print(cited_dict[id_])\n",
    "print('was cited by:')\n",
    "print(cited_by_dict[id_])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f181c",
   "metadata": {},
   "source": [
    "### Create cited and cited_by columns for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6fe3c7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1cb812e1d648bcbed764c54be70769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4086532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the entire docdb_family_id column as a list\n",
    "docdb_family_id_column = list(data['docdb_family_id'])\n",
    "len_ = len(docdb_family_id_column)\n",
    "\n",
    "# Define two empty lists and loop over docdb_family_id_column, creating new cited and cited_by entries for our \n",
    "# DataFrame\n",
    "cited_docdb_family_ids_column = [np.nan] * len_\n",
    "cited_by_docdb_family_ids_column = [np.nan] * len_\n",
    "for i in tqdm(range(len_)):\n",
    "    \n",
    "    try:\n",
    "        cited_docdb_family_ids_column[i] = cited_dict[docdb_family_id_column[i]]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        cited_by_docdb_family_ids_column[i] = cited_by_dict[docdb_family_id_column[i]]\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1386d",
   "metadata": {},
   "source": [
    "### Insert them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f39b728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop('cited_docdb_family_ids', axis = 1, inplace = True)\n",
    "#data.drop('cited_by_docdb_family_ids', axis = 1, inplace = True)\n",
    "#data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ebba8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(1, 'cited_docdb_family_ids', cited_docdb_family_ids_column)\n",
    "data.insert(2, 'cited_by_docdb_family_ids', cited_by_docdb_family_ids_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f21e2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cited_docdb_family_ids</th>\n",
       "      <th>cited_by_docdb_family_ids</th>\n",
       "      <th>docdb_family_id</th>\n",
       "      <th>appln_id</th>\n",
       "      <th>granted</th>\n",
       "      <th>earliest_filing_date</th>\n",
       "      <th>earliest_filing_year</th>\n",
       "      <th>earliest_publn_date</th>\n",
       "      <th>earliest_publn_year</th>\n",
       "      <th>...</th>\n",
       "      <th>psn_id</th>\n",
       "      <th>psn_level</th>\n",
       "      <th>psn_sector</th>\n",
       "      <th>han_id</th>\n",
       "      <th>han_harmonized</th>\n",
       "      <th>ipc_class_levels</th>\n",
       "      <th>ipc_versions</th>\n",
       "      <th>ipc_values</th>\n",
       "      <th>ipc_positions</th>\n",
       "      <th>ipc_gener_auths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2231540</th>\n",
       "      <td>IPF</td>\n",
       "      <td>47068142,6405878,47631176,50065728,51568650,50...</td>\n",
       "      <td>19833515,69640408</td>\n",
       "      <td>1574492</td>\n",
       "      <td>441031337</td>\n",
       "      <td>N</td>\n",
       "      <td>2014-06-13</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015-12-17</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>6239657.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>COMPANY</td>\n",
       "      <td>684387.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A,A,A,A,A,A</td>\n",
       "      <td>2006-01-01,2006-01-01,2006-01-01,2006-01-01,20...</td>\n",
       "      <td>I,I,I,I,I,I</td>\n",
       "      <td>L, , , ,F,L</td>\n",
       "      <td>EP,EP,EP,EP,EP,EP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag                             cited_docdb_family_ids  \\\n",
       "2231540  IPF  47068142,6405878,47631176,50065728,51568650,50...   \n",
       "\n",
       "        cited_by_docdb_family_ids  docdb_family_id   appln_id granted  \\\n",
       "2231540         19833515,69640408          1574492  441031337       N   \n",
       "\n",
       "        earliest_filing_date  earliest_filing_year earliest_publn_date  \\\n",
       "2231540           2014-06-13                  2014          2015-12-17   \n",
       "\n",
       "         earliest_publn_year  ...     psn_id  psn_level psn_sector    han_id  \\\n",
       "2231540                 2015  ...  6239657.0        1.0    COMPANY  684387.0   \n",
       "\n",
       "         han_harmonized ipc_class_levels  \\\n",
       "2231540             1.0      A,A,A,A,A,A   \n",
       "\n",
       "                                              ipc_versions   ipc_values  \\\n",
       "2231540  2006-01-01,2006-01-01,2006-01-01,2006-01-01,20...  I,I,I,I,I,I   \n",
       "\n",
       "        ipc_positions    ipc_gener_auths  \n",
       "2231540   L, , , ,F,L  EP,EP,EP,EP,EP,EP  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35c07b",
   "metadata": {},
   "source": [
    "## Show that ipc_class_symbols has no duplicate entries\n",
    "### This prints nothing if there are no duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fa9281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd294dcecf9a4d4c9b11ca811dc752cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4086532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipc_class_symbols_list = list(data['ipc_class_symbols'])\n",
    "len_ = len(ipc_class_symbols_list)\n",
    "\n",
    "\n",
    "for i in tqdm(range(len_)):\n",
    "        \n",
    "    # Split this string into the ipc class entries it contains, delete duplicates and rejoin it into one string\n",
    "    try:\n",
    "        len_before = len(ipc_class_symbols_list[i])\n",
    "        ipc_class_symbols_list_reduced[i] = ','.join(list(set(ipc_class_symbols_list[i].split(','))))\n",
    "        len_after = len(ipc_class_symbols_list_reduced[i])\n",
    "        \n",
    "        if len_before != len_after:\n",
    "            print(len_before, len_after)\n",
    "            print()\n",
    "            \n",
    "    except Exception as e:\n",
    "        pass\n",
    "        #print(e)\n",
    "        #print(type(e)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-tomato",
   "metadata": {},
   "source": [
    "## Create tags: 'non_active_parts_electrodes_secondary_cells', 'charging', 'flow_classes_query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "572450c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2 - 4. Jan. 2022\n",
    "# Does not save the data as a new dataset but instead tags original dataset\n",
    "\n",
    "def query_tag(data, classes_want, classes_dont_want, or_or):\n",
    "    \"\"\"\n",
    "    Function that takes a dataset, a list of wanted classes and a list of unwanted classes as input and performs a\n",
    "    query (checking each docdb family) with the following logic:\n",
    "    \n",
    "    If or_or = True:\n",
    "        (IPC = classes_want[0] OR classes_want[1] OR ...) \n",
    "        AND  NOT (IPC = classes_dont_want[0]  OR  classes_dont_want[1] OR ...)\n",
    "        \n",
    "    If or_or = False:\n",
    "        (IPC = classes_want[0] AND classes_want[1] AND ...) \n",
    "        AND  NOT (IPC = classes_dont_want[0]  OR  classes_dont_want[1] OR ...)\n",
    "        \n",
    "        (Note that in this case one element classes_want[i] can actually be a list which in itself is processed\n",
    "        with an OR statement! This is to account for the fact that 'H01M   2' has been transferred to 'H01M  50'\n",
    "        in the IPC hierachy.\n",
    "    \n",
    "    Returns: List of docdb_family_ids of families that matched the query\n",
    "    \"\"\"\n",
    "    \n",
    "    error_log = []\n",
    "    \n",
    "    # Define which id to use for searching\n",
    "    id_type = 'docdb_family_id'\n",
    "    \n",
    "    # Initialise list for query results\n",
    "    family_ids_want = set()\n",
    "    \n",
    "    # Get all family_ids\n",
    "    family_ids = pd.unique(data[id_type])\n",
    "    \n",
    "    for family_id in tqdm(family_ids):\n",
    "\n",
    "        data_this_id = data[data[id_type]==family_id]\n",
    "        \n",
    "        classes_this_id = []\n",
    "        for ipc_class_entry in pd.unique(data_this_id.ipc_class_symbols):\n",
    "            \n",
    "            # Some ipc_class_entries are NaN. Skip these ones.\n",
    "            try:\n",
    "                classes_this_id.extend(ipc_class_entry.split(','))\n",
    "            except Exception as e:\n",
    "                #error_log.append(str(family_id)+': '+str(type(e))+' - '+str(e))\n",
    "                error_log.append(str(type(e))+' - '+str(e))\n",
    "                #pass\n",
    "            \n",
    "        classes_this_id = pd.Series(list(set(classes_this_id)))\n",
    "\n",
    "        if len(classes_this_id) > 0:\n",
    "            \n",
    "            # This is the want block\n",
    "            # Apply OR logic in want block\n",
    "            if or_or:\n",
    "                include = False\n",
    "                for i in range(len(classes_want)):\n",
    "                    if classes_this_id.str.match(classes_want[i]).sum()>0:\n",
    "                        include = True\n",
    "                        break\n",
    "            # Apply AND logic in want block.\n",
    "            # Note that 'H01M   2' and 'H01M  50' still need to be connected by an OR. \n",
    "            # See code section below with comment \"This is where the OR statement [...]\".\n",
    "            else:\n",
    "                include = True\n",
    "                for i in range(len(classes_want)):\n",
    "\n",
    "                    if (type(classes_want[i]) is str):\n",
    "\n",
    "                        if classes_this_id.str.match(classes_want[i]).sum()==0:\n",
    "                            include = False\n",
    "                            break\n",
    "                    else:\n",
    "                        # This is where the OR statement for 'H01M   2' and 'H01M  50' is processed.\n",
    "                        # This code only accounts for the case that there is a list inside the list with only 2 elements.\n",
    "                        # I need to implement another loop right here if this changes.\n",
    "                        bool_0 = classes_this_id.str.match(classes_want[i][0]).sum()==0\n",
    "                        bool_1 = classes_this_id.str.match(classes_want[i][1]).sum()==0\n",
    "                        if (bool_0 and bool_1):\n",
    "                            include = False\n",
    "                            break\n",
    "\n",
    "            # This is the don't want block\n",
    "            # Always apply or logic\n",
    "            # Only execute if the want block yielded include = True\n",
    "            if include == True:\n",
    "                for i in range(len(classes_dont_want)):\n",
    "                    if classes_this_id.str.match(classes_dont_want[i]).sum()>0:\n",
    "                        include = False\n",
    "                        break\n",
    "        \n",
    "        else: \n",
    "            include = False\n",
    "\n",
    "        # If the resulting value for include = True, add this family_id to our query result\n",
    "        if include == True:\n",
    "            #data_want = data_want + [data_this_id]\n",
    "            family_ids_want.add(family_id)\n",
    "            \n",
    "    #data_return = pd.concat(data_want, axis = 0)\n",
    "    \n",
    "    return family_ids_want, error_log\n",
    "    #return data_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e2b8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_tag_column(family_ids_to_tag, name, loc):\n",
    "    \n",
    "    len_ = len(data)\n",
    "    family_ids = list(data['docdb_family_id'])\n",
    "    col = [0] * len_\n",
    "\n",
    "    for i in tqdm(range(len_)):\n",
    "\n",
    "        if (family_ids[i] in family_ids_to_tag):\n",
    "            col[i] = 1\n",
    "\n",
    "    # Insert tag column into data\n",
    "    # If it already exists, delete the old version first\n",
    "    if name in list(data):\n",
    "        data.drop(columns = name, inplace = True)\n",
    "    data.insert(loc, name, col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e8522",
   "metadata": {},
   "source": [
    "### Non-active parts, electrodes, secondary cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "auburn-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_want_non_active_parts_electrodes_secondary_cells = ['H01M   2', 'H01M  50', 'H01M   4', 'H01M  10']\n",
    "\n",
    "# Exclude patent families related to primary cells (H01M 6), fuel cells (H01M 8), hybrid cells (H01M 12),\n",
    "# electrochemical current generators (H01M 14), and combinations of electrochemical generators (H01M 16).\n",
    "classes_dont_want_non_active_parts_electrodes_secondary_cells = ['H01M   6', 'H01M   8', 'H01M  12', 'H01M  14', 'H01M  16']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "individual-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dfac8e8326404e91c606ba188d8f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute IPC classes query for collecting all patent families related to Non-active parts, electrodes, or\n",
    "# secondary cells or any combination of them.\n",
    "family_ids_query_non_active_parts_electrodes_secondary_cells, error_log_query_non_active_parts_electrodes_secondary_cells = query_tag(\n",
    "    data,\n",
    "    classes_want_non_active_parts_electrodes_secondary_cells,\n",
    "    classes_dont_want_non_active_parts_electrodes_secondary_cells,\n",
    "    True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07eecb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'AttributeError'> - 'float' object has no attribute 'split'\"}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which errors have occured.\n",
    "# \"<class 'AttributeError'> - 'float' object has no attribute 'split'\" is expected. (Occurs when entry is nan)\n",
    "set(error_log_query_non_active_parts_electrodes_secondary_cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df203447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74cdda9413d4c0aa8a8d06a3af58522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4086532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert tag column\n",
    "insert_tag_column(\n",
    "    family_ids_query_non_active_parts_electrodes_secondary_cells,\n",
    "    'non_active_parts_electrodes_secondary_cells',\n",
    "    0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f35a72",
   "metadata": {},
   "source": [
    "### Charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abd055d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H01M   6',\n",
       " 'H01M   8',\n",
       " 'H01M  12',\n",
       " 'H01M  14',\n",
       " 'H01M  16',\n",
       " 'B60L 53/54',\n",
       " 'B60L 53/55',\n",
       " 'B60L 53/56']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_want_charging = ['H02J   3/32', 'H02J   7', 'B60L  53', 'H01M  10/44']\n",
    "\n",
    "# Exclude what was excluded for non_active_parts_electrodes_secondary_cells and a few more that are related to\n",
    "# fuel cells, capacitors, or mechanical storage\n",
    "classes_dont_want_charging = classes_dont_want_non_active_parts_electrodes_secondary_cells + [\n",
    "    # Charging stations characterised by energy-storage or power-generation means...\n",
    "    'B60L 53/54', # ...Fuel cells\n",
    "    'B60L 53/55', # ...Capacitors\n",
    "    'B60L 53/56' # ...Mechanical storage means, e.g. fly wheels\n",
    "]\n",
    "\n",
    "classes_dont_want_charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0029374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0810c6883644496e871c34b416820751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute IPC classes query for collecting all patent families related to charging of secondary batteries.\n",
    "family_ids_query_charging, error_log_query_charging = query_tag(\n",
    "    data,\n",
    "    classes_want_charging,\n",
    "    classes_dont_want_charging,\n",
    "    True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ebc377e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'AttributeError'> - 'float' object has no attribute 'split'\"}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which errors have occured.\n",
    "# \"<class 'AttributeError'> - 'float' object has no attribute 'split'\" is expected. (Occurs when entry is nan)\n",
    "set(error_log_query_charging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1aafdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b3a8a93374a29bab24ae542b3e720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4086532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert tag column\n",
    "insert_tag_column(\n",
    "    family_ids_query_charging,\n",
    "    'charging',\n",
    "    1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-forest",
   "metadata": {},
   "source": [
    "### Classes query for redox flow and Nickelâhydrogen ('flow_classes_query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "attended-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_want_flow = ['H01M   2', 'H01M  50', 'H01M   4', 'H01M   8', 'H01M  10']\n",
    "classes_dont_want_flow = ['H01M   6', 'H01M  12', 'H01M  14',  'H01M  16']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2d214cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f43319def64c30be99be5c125b7698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute IPC classes query for collecting all patent families that might be related to redox flox or Nickelâhydrogen batteries (further reduction through text query)\n",
    "family_ids_classes_query_flow, error_log_classes_query_flow = query_tag(\n",
    "    data,\n",
    "    classes_want_flow,\n",
    "    classes_dont_want_flow,\n",
    "    True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bizarre-president",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'AttributeError'> - 'float' object has no attribute 'split'\"}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which errors have occured.\n",
    "# \"<class 'AttributeError'> - 'float' object has no attribute 'split'\" is expected. (Occurs when entry is nan)\n",
    "set(error_log_classes_query_flow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d73cb035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1b783c662e40cca04d82a7bc311c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4086532 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert tag column\n",
    "insert_tag_column(\n",
    "    family_ids_classes_query_flow,\n",
    "    'flow_classes_query',\n",
    "    2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce3dc7",
   "metadata": {},
   "source": [
    "## Save this version of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6063f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save battery data (classes query tagged) to csv\n",
    "filename = 'data_batteries_'+current_time_string()+'_classes_query_tagged.csv'\n",
    "data.to_csv(path_or_buf=filename, sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b8309",
   "metadata": {},
   "source": [
    "## Run next two cells if notebook is started from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1713e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "main_path_mac = '/Users/philippmetzger/Documents/GitHub/MA_temp/'\n",
    "main_path_ssd = '/Volumes/Samsung Portable SSD T3 Media/'\n",
    "\n",
    "import sys\n",
    "packages_path = main_path_mac+'/07 Packages'\n",
    "sys.path.append(packages_path)\n",
    "\n",
    "from m_thesis_helpers import (current_time_string,\n",
    "                              image_saver,\n",
    "                              country_labels_dict,\n",
    "                              ctry_code_name_dict,\n",
    "                              message)\n",
    "\n",
    "main_path_mac = '/Users/philippmetzger/Documents/GitHub/MA_temp/'\n",
    "main_path_ssd = '/Volumes/Samsung Portable SSD T3 Media/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b90148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:\n",
      "/Volumes/Samsung Portable SSD T3 Media/Dataset saves/04 From 15 Nov 2021 (release of 2021 Autumn edition)/01 Preprocessed/02 ipf only, classes query tagged/data_batteries_2022-01-06_1121_ipf_only_classes_query_tagged.csv\n"
     ]
    }
   ],
   "source": [
    "# Read battery data (all, tagged) to csv\n",
    "dataset_name = 'data_batteries_2022-01-06_1121_ipf_only_classes_query_tagged'\n",
    "\n",
    "path = main_path_ssd+'Dataset saves/04 From 15 Nov 2021 (release of 2021 Autumn edition)/01 Preprocessed/02 ipf only, classes query tagged/'+dataset_name+'.csv'\n",
    "\n",
    "print('Loading data from:')\n",
    "print(path)\n",
    "\n",
    "data = pd.read_csv(path, delimiter = \";\", low_memory = False, na_values=['', ' ', '  '], keep_default_na = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac281c7a",
   "metadata": {},
   "source": [
    "## Create subsets for use in text queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0706d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_non_active_parts_electrodes_secondary_cells = data[data['non_active_parts_electrodes_secondary_cells'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f87e7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flow_classes_query = data[data['flow_classes_query'] == 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-track",
   "metadata": {},
   "source": [
    "## Create technology tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75982cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_query_tag(data, text_queries_list, technologies_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    text_query_tag version 1:\n",
    "    Version 5 of text_query with the following modifications:\n",
    "    - Now saving ids and not sub datasets\n",
    "    - created variable to_search_this_id and changed 'abstract' variables to 'item' variabes\n",
    "    - changed list additions to .append\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize data structure\n",
    "    ids_dict = {}\n",
    "    for technology_name in technologies_list:\n",
    "        ids_dict[technology_name] = set()\n",
    "    \n",
    "    to_remove = ['<SUB>', '</SUB>', '<SUP>', '</SUP>', '<P>', '<SP>', '</SP>']\n",
    "                \n",
    "    to_remove_spaces = ['\\\\t', '\\\\n', '\\\\r', '\\\\f', '\\\\v', '\\t', '\\n', '\\r', '\\f', '\\v']\n",
    "    \n",
    "    punctuation = '!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~'   \n",
    "\n",
    "    # Define two lists for post-analysis of thrown errors\n",
    "    error_items = []\n",
    "    error_items_in_id = []\n",
    "    removal_error_items = []\n",
    "    removal_error_items_in_id = []\n",
    "\n",
    "    # Define which id to use for searching\n",
    "    id_type = 'docdb_family_id'\n",
    "\n",
    "    # Get all unique ids\n",
    "    ids = pd.unique(data[id_type])\n",
    "\n",
    "    #data_want = []\n",
    "    ids_this_technology = set()\n",
    "\n",
    "    # Loop over all ids\n",
    "    for id_ in tqdm(ids):\n",
    "\n",
    "        data_this_id = data[data[id_type]==id_]\n",
    "        \n",
    "        # Get all distinct abstracts of this family\n",
    "        abstracts_this_id = list(pd.unique(data_this_id[\n",
    "            # Exclude Portuguese because of the word 'nas'\n",
    "            data_this_id['appln_abstract_lg'] != 'pt'\n",
    "        ].appln_abstract))\n",
    "        \n",
    "        # From abstracts delete everything that comes after 'Independent claims are also included for'\n",
    "        abstracts_this_id_altered = []\n",
    "        text_query = 'Independent claims are also included for'\n",
    "        \n",
    "        # Could consider to also exclude everything after. \"An Independent claim is included for\"\n",
    "        # (for example in english abstract of docdb family ID 3521501)\n",
    "        \n",
    "        for abstract in abstracts_this_id:\n",
    "            \n",
    "            try:\n",
    "                reg_ex = re.compile(text_query, re.IGNORECASE)\n",
    "                result = reg_ex.search(abstract)\n",
    "                begin_cutoff = result.span()[0]\n",
    "                abstracts_this_id_altered.append(abstract[:begin_cutoff])\n",
    "            except:\n",
    "                abstracts_this_id_altered.append(abstract)\n",
    "        \n",
    "        # Overwrite old version with new one\n",
    "        abstracts_this_id = abstracts_this_id_altered\n",
    "\n",
    "        # Get all distinct titles of this family\n",
    "        titles_this_id = list(pd.unique(data_this_id[\n",
    "            # Exclude Portuguese because of the word 'nas'\n",
    "            data_this_id['appln_title_lg'] != 'pt'\n",
    "        ].appln_title))\n",
    "           \n",
    "        to_search_this_id = abstracts_this_id + titles_this_id\n",
    "\n",
    "        # Remove to_remove and punctuation\n",
    "        to_search_this_id_altered = []\n",
    "        for this_item in to_search_this_id:\n",
    "                        \n",
    "            try:\n",
    "                \n",
    "                # Remove items listed in to_remove and replace by empty string\n",
    "                for x in to_remove:\n",
    "                    this_item = this_item.replace(x,'')\n",
    "                    \n",
    "                # Remove items listed in to_remove_spaces and replace by one space\n",
    "                for x in to_remove_spaces:\n",
    "                    this_item = this_item.replace(x,' ')\n",
    "                \n",
    "                # Remove punctuation present in punctuation string and replace by one space\n",
    "                for x in punctuation:\n",
    "                    this_item = this_item.replace(x,' ')\n",
    "                    \n",
    "            except:\n",
    "                removal_error_items.append(this_item)\n",
    "                removal_error_items_in_id.append(id_)\n",
    "                \n",
    "            # Save altered string in to_search_this_id_altered\n",
    "            to_search_this_id_altered.append(this_item)\n",
    "            \n",
    "        # Overwrite to_search_this_id with altered version\n",
    "        to_search_this_id = to_search_this_id_altered\n",
    " \n",
    "        # Conduct text queries and save ids that were a hit in the respective set inside ids_dict\n",
    "        for technology_index, text_query_this_technology in enumerate(text_queries_list):\n",
    "            \n",
    "            found = False\n",
    "            \n",
    "            for this_item in to_search_this_id:\n",
    "\n",
    "                for text_query in text_query_this_technology:\n",
    "\n",
    "                    reg_ex = re.compile(text_query, re.IGNORECASE)\n",
    "\n",
    "                    try:\n",
    "                        if reg_ex.search(this_item)!=None:\n",
    "                            found = True\n",
    "                    except:\n",
    "                        error_items.append(this_item)\n",
    "                        error_items_in_id.append(id_)\n",
    "\n",
    "            if found==True:\n",
    "                ids_dict[technologies_list[technology_index]].add(id_)\n",
    "    \n",
    "    return ids_dict, error_items, error_items_in_id, removal_error_items, removal_error_items_in_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9598dccd",
   "metadata": {},
   "source": [
    "### Define regular expressions (text queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e44bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_three_words = '( +\\w+){0,3} +'\n",
    "max_two_words = '( +\\w+){0,2} +'\n",
    "max_one_word = '( +\\w+){0,1} +'\n",
    "beg_or_space = '( +|^)'\n",
    "end_or_space = '( +|$)'\n",
    "space_or_nothing = ' *'\n",
    "space = ' +'\n",
    "\n",
    "# Explanation of above patterns:\n",
    "\"\"\"\n",
    "At most three words between left and right word:\n",
    "max_three_words =\n",
    "    whitespace (any length), string, whitespace (any length), string, whitespace (any length), string, whitespace (any length) \n",
    "    or\n",
    "    whitespace (any length), string, whitespace (any length), string, whitespace (any length)\n",
    "    or\n",
    "    whitespace (any length), string, whitespace (any length)\n",
    "    or\n",
    "    whitespace (any length)\n",
    "    \n",
    "    \n",
    "At most two words between left and right word:\n",
    "max_two_words =\n",
    "    whitespace (any length), string, whitespace (any length), string, whitespace (any length) \n",
    "    or\n",
    "    whitespace (any length), string, whitespace (any length)\n",
    "    or\n",
    "    whitespace (any length)\n",
    "\n",
    "\n",
    "At most one word between left and right word:\n",
    "max_one_word =\n",
    "    whitespace (any length), string, whitespace (any length)\n",
    "    or\n",
    "    whitespace (any length)\n",
    "\n",
    "\n",
    "Space between left and right word or beginning of string:\n",
    "beg_or_space = \n",
    "    whitespace (any length)\n",
    "    or\n",
    "    beginning of string\n",
    "    \n",
    "    \n",
    "Space between left and right word or end of string:\n",
    "end_or_space =\n",
    "    whitespace (any length)\n",
    "    or\n",
    "    end of string\n",
    "    \n",
    "A space of any length or nothing:\n",
    "space_or_nothing\n",
    "\n",
    "A space of any length greater than zero:\n",
    "space\n",
    "\n",
    "\\w - Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].\n",
    "+ - Allows item before to be present once or multiple times\n",
    "{m,n} - m and n are integers. At least m repetitions, and at most n repetitions.\n",
    "^ - Beginning of string\n",
    "$ - End of string\n",
    "| - Or\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Lead-acid:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_lead_acid = ['H01M   2', 'H01M  50', 'H01M   4', 'H01M  10']\n",
    "classes_dont_want_lead_acid = ['H01M   6', 'H01M   8', 'H01M  12', 'H01M  14', 'H01M  16']\n",
    "\n",
    "text_queries_lead_acid = [\n",
    "    beg_or_space+'lead'+max_one_word+'acid'+end_or_space,\n",
    "    beg_or_space+'lead'+max_one_word+'acc',\n",
    "    \n",
    "    beg_or_space+'VRLA'+end_or_space,\n",
    "    beg_or_space+'VLA'+end_or_space,\n",
    "    beg_or_space+'SLA'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'absorbent'+max_one_word+'glass'+max_one_word+'mat'+end_or_space,\n",
    "    beg_or_space+'AGM'+end_or_space,\n",
    "        \n",
    "    beg_or_space+'gel'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'gel'+max_one_word+'batt'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Lithium-air:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_lithium_air = classes_want_lead_acid\n",
    "classes_dont_want_lithium_air = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_lithium_air = [\n",
    "    beg_or_space+'Lithium'+max_one_word+'air'+end_or_space,\n",
    "    beg_or_space+'Li'+max_one_word+'air'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_one_word+'oxygen'+end_or_space,\n",
    "    beg_or_space+'Li'+max_one_word+'O2'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Lithium-ion:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_lithium_ion = classes_want_lead_acid\n",
    "classes_dont_want_lithium_ion = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_lithium_ion = [\n",
    "    beg_or_space+'li'+max_two_words+'ion'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_two_words+'ion'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'LIB'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'Li'+max_one_word+'Po'+end_or_space,\n",
    "    beg_or_space+'LIP'+end_or_space,\n",
    "    beg_or_space+'Li'+max_one_word+'Poly',\n",
    "    beg_or_space+'lithium'+max_one_word+'Poly',\n",
    "    \n",
    "    beg_or_space+'lithium'+max_one_word+'cobalt'+end_or_space,\n",
    "    beg_or_space+'LCO'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'lithium'+max_one_word+'manganese'+end_or_space,\n",
    "    beg_or_space+'LMO'+end_or_space,\n",
    "\n",
    "    beg_or_space+'lithium'+max_one_word+'nickel'+max_one_word+'manganese'+max_one_word+'cobalt',\n",
    "    beg_or_space+'NMC'+end_or_space,\n",
    "    beg_or_space+'LNMC'+end_or_space,\n",
    "    beg_or_space+'NCM'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'lithium'+max_one_word+'iron'+max_one_word+'phosphate'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_one_word+'phosphate'+end_or_space,\n",
    "    beg_or_space+'Li'+max_one_word+'Fe'+max_one_word+'PO'+end_or_space,\n",
    "    beg_or_space+'LFP'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'lithium'+max_one_word+'nickel'+max_one_word+'cobalt'+max_one_word+'aluminium'+end_or_space,\n",
    "    beg_or_space+'NCA'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'lithium'+max_one_word+'titanate'+end_or_space,\n",
    "    beg_or_space+'LTO'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'lithium'+max_one_word+'silicon'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_one_word+'silicon'+max_one_word+'batter'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Lithium-sulfur:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_lithium_sulfur = classes_want_lead_acid\n",
    "classes_dont_want_lithium_sulfur = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_lithium_sulfur = [\n",
    "    beg_or_space+'li'+max_one_word+'S'+end_or_space,\n",
    "    beg_or_space+'li'+max_one_word+'sulphur'+end_or_space,\n",
    "    beg_or_space+'li'+max_one_word+'sulfur'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_one_word+'sulphur'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_one_word+'sulfur'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_one_word+'s'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Other lithium:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_other_lithium = classes_want_lead_acid\n",
    "classes_dont_want_other_lithium = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_other_lithium = [\n",
    "    beg_or_space+'lithium'+max_two_words+'batter',\n",
    "    beg_or_space+'lithium'+max_two_words+'cell'+end_or_space,\n",
    "    beg_or_space+'lithium'+max_two_words+'secondary'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Magnesium-ion:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_magnesium_ion = classes_want_lead_acid\n",
    "classes_dont_want_magnesium_ion = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_magnesium_ion = [\n",
    "    beg_or_space+'magnesium'+max_one_word+'ion'+end_or_space,\n",
    "    beg_or_space+'Mg'+max_one_word+'ion'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nickel-cadmium:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_nickel_cadmium = classes_want_lead_acid\n",
    "classes_dont_want_nickel_cadmium = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_nickel_cadmium = [\n",
    "    beg_or_space+'nickel'+max_one_word+'cadmium'+end_or_space,\n",
    "    beg_or_space+'nickel'+max_one_word+'cd'+end_or_space,\n",
    "    beg_or_space+'Ni'+max_one_word+'cd'+end_or_space,\n",
    "    beg_or_space+'Ni'+max_one_word+'cadmium'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nickel-iron:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_nickel_iron = classes_want_lead_acid\n",
    "classes_dont_want_nickel_iron = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_nickel_iron = [\n",
    "    beg_or_space+'nickel'+max_one_word+'iron'+end_or_space,\n",
    "    beg_or_space+'nickel'+max_one_word+'Fe'+end_or_space,\n",
    "    beg_or_space+'Ni'+max_one_word+'Fe'+end_or_space,\n",
    "    beg_or_space+'Ni'+max_one_word+'iron'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nickel-zinc:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_nickel_zinc = classes_want_lead_acid\n",
    "classes_dont_want_nickel_zinc = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_nickel_zinc = [\n",
    "    beg_or_space+'nickel'+max_one_word+'zinc'+end_or_space,\n",
    "    beg_or_space+'nickel'+max_one_word+'Zn'+end_or_space,\n",
    "    beg_or_space+'Ni'+max_one_word+'Zn'+end_or_space,\n",
    "    beg_or_space+'Ni'+max_one_word+'zinc'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nickel-metal hydride:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_nickel_metal_hydride = classes_want_lead_acid\n",
    "classes_dont_want_nickel_metal_hydride = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_nickel_metal_hydride = [\n",
    "    beg_or_space+'nickel'+max_one_word+'metal'+max_one_word+'hydride'+end_or_space,\n",
    "    beg_or_space+'Ni'+max_one_word+'M'+max_one_word+'H'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Rechargeable alkaline:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_rechargeable_alkaline = classes_want_lead_acid\n",
    "classes_dont_want_rechargeable_alkaline = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_rechargeable_alkaline = [\n",
    "    beg_or_space+'rechargeable'+max_one_word+'alkali(ne){0,1}'+max_one_word+'batter',\n",
    "    beg_or_space+'rechargeable'+max_one_word+'alkali(ne){0,1}'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'alkali(ne){0,1}'+max_one_word+'rechargeable'+end_or_space,\n",
    "    beg_or_space+'rechargeable'+max_one_word+'alkali(ne){0,1}'+max_one_word+'manganese'+end_or_space,\n",
    "    beg_or_space+'RAM'+end_or_space,\n",
    "    beg_or_space+'alkali(ne){0,1}'+max_one_word+'secondary'+end_or_space,\n",
    "    beg_or_space+'secondary'+max_one_word+'alkali(ne){0,1}'+end_or_space,\n",
    "    beg_or_space+'alkali(ne){0,1}'+max_one_word+'storage'+max_one_word+'batter',\n",
    "    beg_or_space+'storage'+max_one_word+'alkali(ne){0,1}'+max_one_word+'batter',\n",
    "    beg_or_space+'alkali(ne){0,1}'+max_one_word+'storage'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'storage'+max_one_word+'alkali(ne){0,1}'+max_one_word+'cell'+end_or_space,\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Sodium-sulfur:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_sodium_sulfur = classes_want_lead_acid\n",
    "classes_dont_want_sodium_sulfur = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_sodium_sulfur = [\n",
    "    beg_or_space+'sodium'+max_one_word+'sulfur'+end_or_space,\n",
    "    beg_or_space+'sodium'+max_one_word+'sulphur'+end_or_space,\n",
    "    beg_or_space+'Na'+max_one_word+'S'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Sodium-ion:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_sodium_ion = classes_want_lead_acid\n",
    "classes_dont_want_sodium_ion = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_sodium_ion = [\n",
    "    beg_or_space+'sodium'+max_one_word+'ion'+end_or_space,\n",
    "    beg_or_space+'Na'+max_one_word+'ion'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Solid-state:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_solid_state = classes_want_lead_acid\n",
    "classes_dont_want_solid_state = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_solid_state = [\n",
    "    beg_or_space+'solid'+max_one_word+'state'+max_one_word+'batter',\n",
    "    beg_or_space+'solid'+max_one_word+'state'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'SSB'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'glass'+max_one_word+'batter'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Aluminium-ion:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_aluminium_ion = classes_want_lead_acid\n",
    "classes_dont_want_aluminium_ion = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_aluminium_ion = [\n",
    "    beg_or_space+'aluminium'+max_one_word+'ion'+max_one_word+'batter',\n",
    "    beg_or_space+'aluminium'+max_one_word+'ion'+max_one_word+'cell'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calcium(-ion):\n",
    "\"\"\"\n",
    "\n",
    "classes_want_calcium_ion = classes_want_lead_acid\n",
    "classes_dont_want_calcium_ion = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_calcium_ion = [\n",
    "    beg_or_space+'calcium'+max_one_word+'ion'+max_one_word+'batter',\n",
    "    beg_or_space+'calcium'+max_one_word+'ion'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'calcium'+max_one_word+'batter',\n",
    "    beg_or_space+'calcium'+max_one_word+'cell'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Organic radical:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_organic_radical = classes_want_lead_acid\n",
    "classes_dont_want_organic_radical = classes_dont_want_lead_acid\n",
    "\n",
    "text_queries_organic_radical = [\n",
    "    beg_or_space+'organic'+max_one_word+'radical'+max_one_word+'batter',\n",
    "    beg_or_space+'organic'+max_one_word+'radical'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'ORB'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Redox flow:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_flow = ['H01M   2', 'H01M  50', 'H01M   4', 'H01M   8', 'H01M  10']\n",
    "classes_dont_want_flow = ['H01M   6', 'H01M  12', 'H01M  14',  'H01M  16']\n",
    "\n",
    "text_queries_flow = [\n",
    "    beg_or_space+'redox'+max_one_word+'flow'+end_or_space,\n",
    "    beg_or_space+'flow'+max_one_word+'batter',\n",
    "    beg_or_space+'rfb'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'vanadium'+max_one_word+'redox'+end_or_space,\n",
    "    beg_or_space+'vrb'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'zinc'+max_one_word+'bromine'+max_one_word+'flow'+end_or_space,\n",
    "    beg_or_space+'zinc'+max_one_word+'bromine'+max_one_word+'batter',\n",
    "    beg_or_space+'zinc'+max_one_word+'bromine'+max_one_word+'cell'+end_or_space,\n",
    "    beg_or_space+'znbr'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'zinc'+max_one_word+'cerium'+max_one_word+'flow'+end_or_space,\n",
    "    beg_or_space+'zinc'+max_one_word+'cerium'+max_one_word+'batter',\n",
    "    beg_or_space+'zinc'+max_one_word+'cerium'+max_one_word+'cell'+end_or_space,\n",
    "        \n",
    "    beg_or_space+'iron'+max_one_word+'chromium'+max_one_word+'flow'+end_or_space,\n",
    "    beg_or_space+'iron'+max_one_word+'chromium'+max_one_word+'batter',\n",
    "    beg_or_space+'iron'+max_one_word+'chromium'+max_one_word+'cell'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'uranium'+max_one_word+'redox'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'polysulfide'+max_one_word+'bromide'+max_one_word+'batter',\n",
    "    beg_or_space+'polysulfide'+max_one_word+'bromide'+max_one_word+'cell'+end_or_space,\n",
    "    \n",
    "    beg_or_space+'hydrogen'+max_one_word+'bromine'+max_one_word+'batter',\n",
    "    beg_or_space+'hydrogen'+max_one_word+'bromine'+max_one_word+'cell'+end_or_space\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Nickelâhydrogen:\n",
    "\"\"\"\n",
    "\n",
    "classes_want_nickel_hydrogen = classes_want_flow\n",
    "classes_dont_want_nickel_hydrogen = classes_dont_want_flow\n",
    "\n",
    "text_queries_nickel_hydrogen = [\n",
    "    beg_or_space+'nickel'+max_one_word+'hydrogen'+max_one_word+'batter',\n",
    "    beg_or_space+'nickel'+max_one_word+'hydrogen'+max_one_word+'cell'+end_or_space\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec4f9f",
   "metadata": {},
   "source": [
    "### Define technology names list and text queries list (classes_want_list and classes_dont_want_list are old code; ignore them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f82ad6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "technologies_list = ['Lead-acid',\n",
    "                     'Lithium-air',\n",
    "                     'Lithium-ion',\n",
    "                     'Lithium-sulfur',\n",
    "                     'Other lithium',\n",
    "                     'Magnesium-ion',\n",
    "                     'Nickel-cadmium',\n",
    "                     'Nickel-iron',\n",
    "                     'Nickel-zinc',\n",
    "                     'Nickel-metal hydride',\n",
    "                     'Rechargeable alkaline',\n",
    "                     'Sodium-sulfur',\n",
    "                     'Sodium-ion',\n",
    "                     'Solid-state',\n",
    "                     'Aluminium-ion',\n",
    "                     'Calcium(-ion)',\n",
    "                     'Organic radical',\n",
    "                     'Redox flow',\n",
    "                     'Nickelâhydrogen']\n",
    "\n",
    "text_queries_list = [text_queries_lead_acid,\n",
    "                     text_queries_lithium_air,\n",
    "                     text_queries_lithium_ion,\n",
    "                     text_queries_lithium_sulfur,\n",
    "                     text_queries_other_lithium,\n",
    "                     text_queries_magnesium_ion,\n",
    "                     text_queries_nickel_cadmium,\n",
    "                     text_queries_nickel_iron,\n",
    "                     text_queries_nickel_zinc,\n",
    "                     text_queries_nickel_metal_hydride,\n",
    "                     text_queries_rechargeable_alkaline,\n",
    "                     text_queries_sodium_sulfur,\n",
    "                     text_queries_sodium_ion,\n",
    "                     text_queries_solid_state,\n",
    "                     text_queries_aluminium_ion,\n",
    "                     text_queries_calcium_ion,\n",
    "                     text_queries_organic_radical,\n",
    "                     text_queries_flow,\n",
    "                     text_queries_nickel_hydrogen]\n",
    "\n",
    "classes_want_list = [classes_want_lead_acid,\n",
    "                     classes_want_lithium_air,\n",
    "                     classes_want_lithium_ion,\n",
    "                     classes_want_lithium_sulfur,\n",
    "                     classes_want_other_lithium,\n",
    "                     classes_want_magnesium_ion,\n",
    "                     classes_want_nickel_cadmium,\n",
    "                     classes_want_nickel_iron,\n",
    "                     classes_want_nickel_zinc,\n",
    "                     classes_want_nickel_metal_hydride,\n",
    "                     classes_want_rechargeable_alkaline,\n",
    "                     classes_want_sodium_sulfur,\n",
    "                     classes_want_sodium_ion,\n",
    "                     classes_want_solid_state,\n",
    "                     classes_want_aluminium_ion,\n",
    "                     classes_want_calcium_ion,\n",
    "                     classes_want_organic_radical,\n",
    "                     classes_want_flow,\n",
    "                     classes_want_nickel_hydrogen]\n",
    "\n",
    "classes_dont_want_list = [classes_dont_want_lead_acid,\n",
    "                          classes_dont_want_lithium_air,\n",
    "                          classes_dont_want_lithium_ion,\n",
    "                          classes_dont_want_lithium_sulfur,\n",
    "                          classes_dont_want_other_lithium,\n",
    "                          classes_dont_want_magnesium_ion,\n",
    "                          classes_dont_want_nickel_cadmium,\n",
    "                          classes_dont_want_nickel_iron,\n",
    "                          classes_dont_want_nickel_zinc,\n",
    "                          classes_dont_want_nickel_metal_hydride,\n",
    "                          classes_dont_want_rechargeable_alkaline,\n",
    "                          classes_dont_want_sodium_sulfur,\n",
    "                          classes_dont_want_sodium_ion,\n",
    "                          classes_dont_want_solid_state,\n",
    "                          classes_dont_want_aluminium_ion,\n",
    "                          classes_dont_want_calcium_ion,\n",
    "                          classes_dont_want_organic_radical,\n",
    "                          classes_dont_want_flow,\n",
    "                          classes_dont_want_nickel_hydrogen]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd066a5",
   "metadata": {},
   "source": [
    "### Create dictionaries with class affiliations for all technologies except Redox flow and Nickel-hydrogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "069a38b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f27b2439ff04f1d968e8e7f78adfc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/304909 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Text queries (tags) for all technologies except Redox flow and Nickel-hydrogen.\n",
    "\n",
    "text_query_results_dict, error_items, error_items_in_id, punctuation_error_items, punctuation_error_items_in_id = text_query_tag(\n",
    "    data_non_active_parts_electrodes_secondary_cells,\n",
    "    text_queries_list[:-2],\n",
    "    technologies_list[:-2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635425e",
   "metadata": {},
   "source": [
    "### Create dictionaries with class affiliations for Redox flow and Nickel-hydrogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94703536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f168c7875a574ddd9a852e663d645264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/402409 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Text queries (tags) for Redox flow and Nickel-hydrogen.\n",
    "\n",
    "text_query_results_dict_Flow, error_items_Flow, error_items_in_id_Flow, punctuation_error_items_Flow, punctuation_error_items_in_id_Flow = text_query_tag(\n",
    "    data_flow_classes_query,\n",
    "    text_queries_list[-2:],\n",
    "    technologies_list[-2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b48dc",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "118ec2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lead-acid', 'Lithium-air', 'Lithium-ion', 'Lithium-sulfur', 'Other lithium', 'Magnesium-ion', 'Nickel-cadmium', 'Nickel-iron', 'Nickel-zinc', 'Nickel-metal hydride', 'Rechargeable alkaline', 'Sodium-sulfur', 'Sodium-ion', 'Solid-state', 'Aluminium-ion', 'Calcium(-ion)', 'Organic radical']\n",
      "\n",
      "['Lead-acid', 'Lithium-air', 'Lithium-ion', 'Lithium-sulfur', 'Other lithium', 'Magnesium-ion', 'Nickel-cadmium', 'Nickel-iron', 'Nickel-zinc', 'Nickel-metal hydride', 'Rechargeable alkaline', 'Sodium-sulfur', 'Sodium-ion', 'Solid-state', 'Aluminium-ion', 'Calcium(-ion)', 'Organic radical', 'Redox flow']\n",
      "\n",
      "['Lead-acid', 'Lithium-air', 'Lithium-ion', 'Lithium-sulfur', 'Other lithium', 'Magnesium-ion', 'Nickel-cadmium', 'Nickel-iron', 'Nickel-zinc', 'Nickel-metal hydride', 'Rechargeable alkaline', 'Sodium-sulfur', 'Sodium-ion', 'Solid-state', 'Aluminium-ion', 'Calcium(-ion)', 'Organic radical', 'Redox flow', 'Nickelâhydrogen']\n"
     ]
    }
   ],
   "source": [
    "print(list(text_query_results_dict))\n",
    "print()\n",
    "text_query_results_dict['Redox flow'] = text_query_results_dict_Flow['Redox flow']\n",
    "print(list(text_query_results_dict))\n",
    "print()\n",
    "\n",
    "text_query_results_dict['Nickelâhydrogen'] = text_query_results_dict_Flow['Nickelâhydrogen']\n",
    "print(list(text_query_results_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c482974",
   "metadata": {},
   "source": [
    "### Delete family IDs from 'Other lithium and lithium-ion' that also appear in any of the other Lithium categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6192b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other lithium\n",
      "['Lithium-air', 'Lithium-ion', 'Lithium-sulfur']\n"
     ]
    }
   ],
   "source": [
    "other_index = 4\n",
    "print(technologies_list[other_index])\n",
    "\n",
    "three_lithium = technologies_list[1:other_index]\n",
    "three_lithium_indices_range = range(1,other_index)\n",
    "print(three_lithium)\n",
    "\n",
    "if True:\n",
    "    \n",
    "    to_reduce = text_query_results_dict[technologies_list[other_index]]\n",
    "    for i in three_lithium_indices_range:\n",
    "        to_reduce = to_reduce.difference(text_query_results_dict[technologies_list[i]])\n",
    "\n",
    "    text_query_results_dict[technologies_list[other_index]] = to_reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f62aa",
   "metadata": {},
   "source": [
    "### Delete family IDs from all other categories if they appear in Solid-state\n",
    "#### Also print how many families each category contained before and after removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00f60726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solid-state\n",
      "\n",
      "['Lead-acid', 'Lithium-air', 'Lithium-ion', 'Lithium-sulfur', 'Other lithium', 'Magnesium-ion', 'Nickel-cadmium', 'Nickel-iron', 'Nickel-zinc', 'Nickel-metal hydride', 'Rechargeable alkaline', 'Sodium-sulfur', 'Sodium-ion', 'Aluminium-ion', 'Calcium(-ion)', 'Organic radical', 'Redox flow', 'Nickelâhydrogen']\n",
      "\n",
      "Lead-acid\n",
      "10093\n",
      "10086\n",
      "Lithium-air\n",
      "319\n",
      "313\n",
      "Lithium-ion\n",
      "55789\n",
      "55521\n",
      "Lithium-sulfur\n",
      "2685\n",
      "2657\n",
      "Other lithium\n",
      "27391\n",
      "27224\n",
      "Magnesium-ion\n",
      "172\n",
      "172\n",
      "Nickel-cadmium\n",
      "340\n",
      "340\n",
      "Nickel-iron\n",
      "561\n",
      "560\n",
      "Nickel-zinc\n",
      "500\n",
      "498\n",
      "Nickel-metal hydride\n",
      "671\n",
      "670\n",
      "Rechargeable alkaline\n",
      "1886\n",
      "1885\n",
      "Sodium-sulfur\n",
      "639\n",
      "639\n",
      "Sodium-ion\n",
      "2070\n",
      "2057\n",
      "Aluminium-ion\n",
      "21\n",
      "21\n",
      "Calcium(-ion)\n",
      "34\n",
      "34\n",
      "Organic radical\n",
      "15\n",
      "15\n",
      "Redox flow\n",
      "3159\n",
      "3159\n",
      "Nickelâhydrogen\n",
      "1537\n",
      "1537\n"
     ]
    }
   ],
   "source": [
    "ssb_name = 'Solid-state'\n",
    "\n",
    "ssb_index = technologies_list.index('Solid-state')\n",
    "print(technologies_list[ssb_index])\n",
    "print()\n",
    "\n",
    "not_ssb = technologies_list[:ssb_index] + technologies_list[ssb_index + 1:]\n",
    "print(not_ssb)\n",
    "print()\n",
    "\n",
    "if True:\n",
    "\n",
    "    ssb = text_query_results_dict[ssb_name]\n",
    "\n",
    "    for technology in not_ssb:\n",
    "        print(technology)\n",
    "        print(len(text_query_results_dict[technology]))\n",
    "        text_query_results_dict[technology] = text_query_results_dict[technology].difference(text_query_results_dict[ssb_name])\n",
    "        print(len(text_query_results_dict[technology]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6314516",
   "metadata": {},
   "source": [
    "### Create technology tags columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "41218c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54957c3e36784d91896f1e785b199941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docdb_family_id_col = list(data['docdb_family_id'])\n",
    "\n",
    "for technology in tqdm(technologies_list):\n",
    "    \n",
    "    new_col = [0] * len(data)\n",
    "    \n",
    "    for i, item in enumerate(docdb_family_id_col):\n",
    "        \n",
    "        if item in text_query_results_dict[technology]:\n",
    "            \n",
    "            new_col[i] = 1\n",
    "         \n",
    "    new_col_name = 'is_'+technology\n",
    "    data[new_col_name] = new_col\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063f0d0",
   "metadata": {},
   "source": [
    "### Compute classification coverage and overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d6e8f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4086532\n",
      "1483954\n"
     ]
    }
   ],
   "source": [
    "a = (data['non_active_parts_electrodes_secondary_cells'] == 1)\n",
    "b = (data['charging'] == 1)\n",
    "c = (data['is_Redox flow'] == 1)\n",
    "d = (data['is_Nickelâhydrogen'] == 1)\n",
    "e = (data['tag'] == 'IPF')\n",
    "\n",
    "data_reduced = data[(a | b | c | d) & e]\n",
    "\n",
    "print(len(data))\n",
    "print(len(data_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2f100",
   "metadata": {},
   "source": [
    "#### Compute coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "05d38f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16773\n",
      "0.1791853173373786\n"
     ]
    }
   ],
   "source": [
    "family_ids_reduced = set(data_reduced['docdb_family_id'])\n",
    "\n",
    "num_all = len(set(family_ids_reduced))\n",
    "\n",
    "all_classified_family_ids = set()\n",
    "for item in list(text_query_results_dict):\n",
    "    \n",
    "    all_classified_family_ids = all_classified_family_ids.union(text_query_results_dict[item])\n",
    "    \n",
    "all_classified_family_ids = all_classified_family_ids.intersection(family_ids_reduced)\n",
    "\n",
    "num_classified = len(all_classified_family_ids)\n",
    "\n",
    "print(num_classified)\n",
    "print(num_classified / num_all)\n",
    "\n",
    "# Is less because there is Charging now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c60d8d",
   "metadata": {},
   "source": [
    "#### Compute overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92dfc374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568\n",
      "0.006067922270770349\n"
     ]
    }
   ],
   "source": [
    "intersection_family_ids = set()\n",
    "technologies = list(text_query_results_dict)\n",
    "\n",
    "for i in range(len(technologies)):\n",
    "    \n",
    "    for j in range(len(technologies)):\n",
    "        \n",
    "        if i != j:\n",
    "            \n",
    "            a = text_query_results_dict[technologies[i]]\n",
    "            b = text_query_results_dict[technologies[j]]\n",
    "\n",
    "            intersection_family_ids = intersection_family_ids.union(a.intersection(b))\n",
    "\n",
    "intersection_family_ids = intersection_family_ids.intersection(family_ids_reduced)\n",
    "\n",
    "num_family_ids_intersection = len(intersection_family_ids)\n",
    "print(num_family_ids_intersection)\n",
    "print(num_family_ids_intersection / num_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05fd80",
   "metadata": {},
   "source": [
    "## Create a column that contains sum of all one-hot technology columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "976840fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_Lead-acid', 'is_Lithium-air', 'is_Lithium-ion', 'is_Lithium-sulfur', 'is_Other lithium', 'is_Magnesium-ion', 'is_Nickel-cadmium', 'is_Nickel-iron', 'is_Nickel-zinc', 'is_Nickel-metal hydride', 'is_Rechargeable alkaline', 'is_Sodium-sulfur', 'is_Sodium-ion', 'is_Solid-state', 'is_Aluminium-ion', 'is_Calcium(-ion)', 'is_Organic radical', 'is_Redox flow', 'is_Nickelâhydrogen']\n"
     ]
    }
   ],
   "source": [
    "# Get names of one-hot technology columns\n",
    "colnames = pd.Series(list(data))\n",
    "colnames = list(colnames[colnames.str.match('is_')])\n",
    "print(colnames)\n",
    "\n",
    "data['technologies_one_hot_sum'] = data[colnames].sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d52607",
   "metadata": {},
   "source": [
    "## In person_ctry_code: Replace 'OH' (Ohio) entry with 'US'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8a2c1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392306"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['person_ctry_code'] == 'US'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d0237ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1301523    OH\n",
       "3910630    OH\n",
       "Name: person_ctry_code, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['person_ctry_code'] == 'OH', 'person_ctry_code']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23ec9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[data['person_ctry_code'] == 'OH', 'person_ctry_code'] = 'US'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fb18147d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392308"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['person_ctry_code'] == 'US'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f7b27c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: person_ctry_code, dtype: object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['person_ctry_code'] == 'OH', 'person_ctry_code']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff68074",
   "metadata": {},
   "source": [
    "## Save final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54b208b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save battery data (IPF only, classes query and technologies tagged) to csv\n",
    "filename = 'data_batteries_'+current_time_string()+'.csv'\n",
    "data.to_csv(path_or_buf=filename, sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b7079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74564f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885f945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
